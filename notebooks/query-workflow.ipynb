{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4be03e",
   "metadata": {},
   "source": [
    "# resultsDB Query \n",
    "\n",
    "###  Kat Nykiel, Alejandro Strachan\n",
    "School of Materials Engineering and Birck Nanotechnology Center, Purdue University, West Lafayette, Indiana 47907, United States\n",
    "\n",
    "This notebook demonstrates how to query results of the wflowingestor tool, and perform analysis to extract additional features for machine learning. Here, we use a high-throughput dataset of hexagonal, layered carbides which have previously been loaded into the wflowingestor tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9307ecc3",
   "metadata": {},
   "source": [
    "## Load Sim2L Results\n",
    "We start by querying resultsDB for all DTM_MAX simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b479d381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T14:53:53.293749Z",
     "start_time": "2023-10-31T14:53:35.146912Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pymatgen.core import Structure, Composition\n",
    "from pymatgen.core.periodic_table import Element\n",
    "from pymatgen.io.vasp.inputs import Poscar, Incar, Kpoints\n",
    "\n",
    "\n",
    "# Import nanoHUB-specific libraries\n",
    "import nanohubremote as nr\n",
    "from simtool import findInstalledSimToolNotebooks,searchForSimTool\n",
    "from simtool import getSimToolInputs,getSimToolOutputs,Run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2214e6b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T14:53:53.907737Z",
     "start_time": "2023-10-31T14:53:53.299139Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a nanoHUB web services session\n",
    "auth_data = {\n",
    "    'grant_type' : 'tool',\n",
    "}\n",
    "with open(os.environ[\"SESSIONDIR\"]+\"/resources\") as file:\n",
    "    lines = [line.split(\" \", 1) for line in file.readlines()]\n",
    "    properties = {line[0].strip(): line[1].strip() for line in lines if len(line)==2}\n",
    "    auth_data[\"sessiontoken\"] = properties[\"session_token\"]\n",
    "    auth_data[\"sessionnum\"] = properties[\"sessionid\"]\n",
    "    \n",
    "session = nr.Sim2l(auth_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee625d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T14:53:56.861989Z",
     "start_time": "2023-10-31T14:53:53.912531Z"
    }
   },
   "outputs": [],
   "source": [
    "# Query the vaspingestor tool for all runs submitted by Kat Nykiel with the DTM_MAX tag\n",
    "tool = 'vaspingestor'\n",
    "\n",
    "installedSimToolNotebooks = findInstalledSimToolNotebooks(tool,returnString=True)\n",
    "print(installedSimToolNotebooks)\n",
    "cellrelaxdft = searchForSimTool(tool)\n",
    "\n",
    "req_json = session.requestPost('results/dbexplorer/search?simtool=true', data={ 'filters': '[{\"field\": \"input.author\", \"operation\": \"=\", \"value\": \"Kat '\n",
    "             'Nykiel\"},{\"field\": \"input.dataset\", \"operation\": \"=\", \"value\": \"DTM_MAX\"}]',\n",
    "  'limit': 10000,\n",
    "  'results': '['\n",
    "             '\"output.XC_functional\"]',\n",
    "  'revision': 0,\n",
    "  'tool': 'vaspingestor'}, timeout=20) # QUERY\n",
    "req_json = req_json.json()\n",
    "data = pd.DataFrame(req_json['results']).dropna().reset_index(drop=True)\n",
    "print(f'data size: {data.shape[0]}')\n",
    "squids = data['squid'].values\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfbd841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T14:56:46.894346Z",
     "start_time": "2023-10-31T14:53:56.864529Z"
    }
   },
   "outputs": [],
   "source": [
    "# Obtain Sim2L outputs, for all versions published. If we want a specific tool version, we can filter only for squids with a specific revision name, ex. 'r7'\n",
    "req_jsons = []\n",
    " \n",
    "for ids in np.array_split(squids,50):\n",
    "    search = {\n",
    "        'tool':'vaspingestor', \n",
    "        'filters':json.dumps([\n",
    "            {'field':'squid','operation':'in','value': str(tuple(ids))},\n",
    "        ]),\n",
    "        'results':json.dumps([\n",
    "            \"output.structure\", \"output.composition\", \n",
    "                 \"output.lattice_parameters\", \"output.lattice_angles\", \n",
    "                 \"output.energy\", \"output.forces\", \"output.max_force\", \n",
    "                 \"output.rms_force\", \"output.KPOINTS\", \"output.ENCUT\", \n",
    "                 \"output.XC_functional\"\n",
    "        ]),\n",
    "        'simtool' : 1,\n",
    "        'limit' : 500\n",
    "    }\n",
    "    req_json = session.requestPost('results/dbexplorer/search', data=search)\n",
    "    req_json = req_json.json()\n",
    "    req_jsons.append(req_json)\n",
    "    \n",
    "req_dfs = []\n",
    "for req_json in req_jsons:\n",
    "    req_dfs.append(pd.DataFrame(req_json['results']))\n",
    "results_df = pd.concat(req_dfs)\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855bc82e",
   "metadata": {},
   "source": [
    "## Extract additional features\n",
    "Next, we extract additional features not stored in the Sim2L. These are features which either depend on outside simulations (formation energy, cohesive energy) or are MAX-specfic (bond lengths, interplanar distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff5705",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T14:56:47.008917Z",
     "start_time": "2023-10-31T14:56:46.897271Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove unneccesary columns, strip 'output.' from column names\n",
    "results_df.drop('squid',axis=1,inplace=True)\n",
    "\n",
    "# create a dictionary to map old column names to new column names\n",
    "new_col_names = {col: col.replace('output.', '') for col in results_df.columns if col.startswith('output.')}\n",
    "\n",
    "# rename columns using the dictionary created above\n",
    "results_df.rename(columns=new_col_names, inplace=True)\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba2b659",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T14:57:32.013663Z",
     "start_time": "2023-10-31T14:56:47.011820Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_features(doc, e_df):\n",
    "    \"\"\"get set of extended features from Sim2L\n",
    "\n",
    "    Args:\n",
    "        doc (dict): row of pandas df from vaspingestor sim2L\n",
    "        e_df (DataFrame): Dataframe containing formation/cohesive energy values\n",
    "        \n",
    "    Returns:\n",
    "        features (dict): extracted feature dictionary\n",
    "    \"\"\"    \n",
    "\n",
    "    features = {}\n",
    "    \n",
    "    # Build structure object\n",
    "    struct = Structure.from_dict(doc['structure'])\n",
    "    n_map = {8:1,12:2,16:3}\n",
    "    n = n_map[struct.num_sites]\n",
    "    \n",
    "    # Formation and cohesive energies\n",
    "    comp_df = pd.DataFrame.from_dict(doc['composition'], orient='index', columns=['n'])\n",
    "    elements_df = e_df.set_index('element')\n",
    "    E_form = (comp_df['n'] * elements_df.loc[comp_df.index]['formation_energy']).sum()\n",
    "    E_coh = (comp_df['n'] * elements_df.loc[comp_df.index]['cohesive_energy']).sum()\n",
    "        \n",
    "    features['formation_energy_per_atom'] = (doc['energy'] - E_form)/struct.num_sites\n",
    "    features['cohesive_energy_per_atom'] = (doc['energy'] - E_coh)/struct.num_sites\n",
    "    \n",
    "    # Bond lengths\n",
    "    # r_MX\n",
    "    sites = {1:[0,6],2:[5,10],3:[7,13]}\n",
    "    features['r_MX'] = struct.get_distance(*sites[n])\n",
    "    # r_MA\n",
    "    sites = {1:[0,5],2:[3,6],3:[3,9]}\n",
    "    features['r_MA'] = struct.get_distance(*sites[n])\n",
    "\n",
    "    # Interplanar distances\n",
    "    # d_AA\n",
    "    sites = {1:[4,5],2:[6,7],3:[8,9]}\n",
    "    features['d_AA'] = get_z_distance(struct, *sites[n])\n",
    "    # d_MM\n",
    "    sites = {1:[0,2],2:[2,3],3:[1,3]}\n",
    "    features['d_MM'] = get_z_distance(struct, *sites[n])\n",
    "    # d_MX\n",
    "    sites = {1:[0,6],2:[5,10],3:[1,13]}\n",
    "    features['d_MX'] = get_z_distance(struct, *sites[n])\n",
    "    # d_XA\n",
    "    sites = {1:[5,6],2:[6,11],3:[8,13]}\n",
    "    features['d_XA'] = get_z_distance(struct, *sites[n])\n",
    "\n",
    "    # Add a few more features for plotting\n",
    "    features['c']=struct.lattice.abc[2]\n",
    "    species= [site.specie for site in struct]\n",
    "    uniques, i = np.unique(species,return_index=True)\n",
    "    sort_i = sorted(i)\n",
    "    elements = [s.symbol for s in [species[i] for i in sort_i]] \n",
    "    \n",
    "    if len(elements) == 4:\n",
    "        features['M1'] = elements[0]\n",
    "        features['M2'] = elements[1]\n",
    "        features['A'] = elements[2]\n",
    "        features['X'] = elements[3]\n",
    "    \n",
    "    elif len(elements) == 3:\n",
    "        features['M1'] = elements[0]\n",
    "        features['M2'] = elements[0]\n",
    "        features['A'] = elements[1]\n",
    "        features['X'] = elements[2]\n",
    "        \n",
    "    features['n']=n\n",
    "\n",
    "    return features\n",
    "\n",
    "def get_z_distance(structure, site_idx1, site_idx2):\n",
    "    # return distance along z axis betwen two sites in Structure object\n",
    "    site1 = structure[site_idx1]\n",
    "    site2 = structure[site_idx2]\n",
    "    z_distance = abs(site1.coords[2] - site2.coords[2])\n",
    "    return z_distance\n",
    "\n",
    "with open('energies.csv') as f:\n",
    "    e_df = pd.read_csv(f)\n",
    "\n",
    "features = []\n",
    "\n",
    "for index, doc in results_df.iterrows():\n",
    "    features.append(get_features(doc, e_df))\n",
    "\n",
    "feature_df = pd.DataFrame(features)\n",
    "feature_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cabddc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T14:57:32.129955Z",
     "start_time": "2023-10-31T14:57:32.019402Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add extracted features to results_df\n",
    "DTM_df = pd.concat([results_df.reset_index(),feature_df.reset_index()],axis=1)\n",
    "DTM_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67d6511",
   "metadata": {},
   "source": [
    "## Visualize Dataset\n",
    "Finally, we provide several plots to visualize the wide domain of this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a4c83",
   "metadata": {},
   "source": [
    "### Scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dacc267",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T14:57:33.228249Z",
     "start_time": "2023-10-31T14:57:32.133975Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate 4 scatter plots of the data, colored by primary M', A, X elements and n number of layers\n",
    "for i,color in enumerate(['n','M1','A','X',]):\n",
    "    titles = ['n','M\\'','A','X']\n",
    "    fig=go.Figure()\n",
    "    metals = DTM_df[color].unique()\n",
    "    colors = px.colors.qualitative.Prism\n",
    "    color_dict = dict(zip(metals,colors))\n",
    "    for metal in metals:\n",
    "        sdf = DTM_df[DTM_df[color]==metal]\n",
    "        try:\n",
    "            fig.add_trace(go.Scatter(x=sdf['c'],y=sdf['formation_energy_per_atom'], mode='markers',marker = {'color':color_dict[metal],'size':4}, name=str(metal))) #,col=i%2+1, row = i//2+1)\n",
    "        except KeyError:\n",
    "            print(f\"Could not generate a plot for {metal}\")\n",
    "    fig.update_layout(\n",
    "        xaxis_title='c (Å)',\n",
    "        yaxis_title='formation energy (eV/atom)',\n",
    "        # title=,\n",
    "#         template='simple_white',\n",
    "        width=600,\n",
    "        height=600,\n",
    "        font_size=20,\n",
    "#         plot_bgcolor='white',\n",
    "        legend=dict(x=.9,y=0.5,itemsizing='constant',title=titles[i])\n",
    "    )\n",
    "    fig.add_shape(type='line', x0=15.8, y0=-2.5, x1=15.8, y1=0.5, line=dict(dash='dot',color='black'))\n",
    "    fig.add_shape(type='line', x0=21.1, y0=-2.5, x1=21.1, y1=0.5, line=dict(dash='dot',color='black'))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee47660e",
   "metadata": {},
   "source": [
    "### Violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a3a435",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T14:57:35.108091Z",
     "start_time": "2023-10-31T14:57:33.231206Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "metals = DTM_df.M1.unique()\n",
    "means = []\n",
    "for metal in metals:\n",
    "    means.append(np.mean(DTM_df[DTM_df['M1']==metal].formation_energy_per_atom.values))\n",
    "metals = [x for _, x in sorted(zip(means,metals))]\n",
    "for metal in metals:\n",
    "    fig.add_trace(go.Violin(x=DTM_df['M1'][DTM_df['M1']==metal][DTM_df['X']=='C'],y=DTM_df['formation_energy_per_atom'][DTM_df['M1']==metal][DTM_df['X']=='C'],name=f'{metal},C', side='positive',legendgroup='C',scalegroup='C',line_color='blue'))\n",
    "    fig.add_trace(go.Violin(x=DTM_df['M1'][DTM_df['M1']==metal][DTM_df['X']=='N'],y=DTM_df['formation_energy_per_atom'][DTM_df['M1']==metal][DTM_df['X']=='N'],name=f'{metal},N', side='negative',legendgroup='N',scalegroup='N',line_color='orange'))\n",
    "fig.update_traces(\n",
    "    meanline_visible=False,\n",
    "    points=False\n",
    ")\n",
    "fig.update_layout(\n",
    "    violingap=0,\n",
    "    violinmode='overlay',\n",
    "    xaxis_title='M\\' element',\n",
    "    yaxis_title='formation energy (eV/atom)',\n",
    "    # title='Formation energy vs. transition metal element',\n",
    "    template='simple_white',\n",
    "    showlegend=False,\n",
    "    font_size=16,\n",
    "    yaxis_range = [-3.5,1]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cadabb",
   "metadata": {},
   "source": [
    "### Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a8a61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T14:57:36.310139Z",
     "start_time": "2023-10-31T14:57:35.111176Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "X_list = ['C','N']\n",
    "for X in X_list:\n",
    "\n",
    "    fig = make_subplots(rows=3, cols = 4, subplot_titles = [\"Al\",\"Si\",\"P\",\"S\",\"Ga\",\"Ge\",\"As\",\"Cd\",\"In\",\"Sn\",\"Tl\",\"Pb\"])\n",
    "\n",
    "    for f,A in enumerate([\"Al\",\"Si\",\"P\",\"S\",\"Ga\",\"Ge\",\"As\",\"Cd\",\"In\",\"Sn\",\"Tl\",\"Pb\"]):\n",
    "\n",
    "        A_df = DTM_df[DTM_df.A==A]\n",
    "        A_df = A_df[A_df.X==X]\n",
    "\n",
    "        # create a pivot table that maps col2 values to each unique col1 value\n",
    "        pivot = A_df.pivot_table(values='formation_energy_per_atom', index='M1', columns='M2')\n",
    "\n",
    "        # get the unique values of col1 and col2 from the original dataframe\n",
    "        x_labels = [\"Sc\",\"Ti\",\"V\",\"Cr\",\"Mn\",\"Zr\",\"Nb\",\"Mo\",\"Hf\",\"Ta\",\"W\"]\n",
    "        y_labels = x_labels\n",
    "\n",
    "        # create a list of dictionaries representing each row in the heatmap\n",
    "        rows = []\n",
    "        for i in range(len(y_labels)):\n",
    "            row = {'y': y_labels[i]}\n",
    "            for j in range(len(x_labels)):\n",
    "                value = pivot.loc[y_labels[i], x_labels[j]]\n",
    "                row[x_labels[j]] = value\n",
    "            rows.append(row)\n",
    "\n",
    "        # define the heatmap trace using the rows list and axis labels\n",
    "        fig.add_trace(go.Heatmap(z=[list(row.values())[1:] for row in rows],\n",
    "                        x=list(x_labels),\n",
    "                        y=list(y_labels),\n",
    "                        name=f'A={A}', coloraxis='coloraxis'),col = f%4+1, row = f//4+1)\n",
    "\n",
    "    fig.for_each_annotation(lambda ann: ann.update(font=dict(size=22)))\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(4):\n",
    "            fig.update_xaxes(title_text='M\\' element', row=i+1, col = j+1)\n",
    "            fig.update_yaxes(title_text='M\\'\\' element', row=i+1, col=j+1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        template='simple_white',\n",
    "        xaxis_title='M\\' element',\n",
    "        yaxis_title='M\\'\\' element',\n",
    "        width=1600,\n",
    "        height=1000,\n",
    "        title=f'formation energy for {X}-based MAX phases')\n",
    "    fig.update_coloraxes(colorbar_title=dict(text='E<sub>form</sub>(eV/atom)'),colorbar_title_font_size=16)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51219114",
   "metadata": {},
   "source": [
    "## Re-building input files from Sim2L\n",
    "An important part of FAIR science is to provide the necessary information to re-create simulations. The vaspingestor Sim2L contains within it the information required to replicate our DTM MAX VASP workflow, and the example below demonstrates how to generate the INCAR, KPOINTS, and POSCAR files, in addition to specifying the required POTCAR files for VASP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e864f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T14:58:50.870601Z",
     "start_time": "2023-10-31T14:58:48.550561Z"
    }
   },
   "outputs": [],
   "source": [
    "# Query for an arbitrary result from the Sim2L database\n",
    "req_json = session.requestPost('results/dbexplorer/search?simtool=true', data={ 'filters': '[{\"field\": \"input.author\", \"operation\": \"=\", \"value\": \"Kat '\n",
    "             'Nykiel\"},{\"field\": \"input.dataset\", \"operation\": \"=\", \"value\": \"DTM_MAX\"}]',\n",
    "  'limit': 1,\n",
    "  'results': '['\n",
    "             '\"input.doc\", \"output.structure\", \"output.KPOINTS\", \"output.energy\"]',\n",
    "  'revision': 0,\n",
    "  'tool': 'vaspingestor'}, timeout=20) # QUERY\n",
    "\n",
    "req_json = req_json.json()\n",
    "data = pd.DataFrame(req_json['results']).dropna().reset_index(drop=True)\n",
    "run = data.iloc[0]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb5c896",
   "metadata": {},
   "source": [
    "### POSCAR file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe7e9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T14:59:10.353323Z",
     "start_time": "2023-10-31T14:59:10.344233Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get structure object from results\n",
    "structure = Structure.from_dict(run['output.structure'])\n",
    "\n",
    "# Create a Poscar object from the Structure object\n",
    "poscar = Poscar(structure)\n",
    "\n",
    "# Write the POSCAR file to disk. Here, we just print it instead\n",
    "# poscar.write_file('POSCAR')\n",
    "print(poscar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b803ca9",
   "metadata": {},
   "source": [
    "### INCAR file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4155ae5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T14:59:29.858908Z",
     "start_time": "2023-10-31T14:59:29.853534Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get Incar object from Sim2L (here, we use a single-point calculation)\n",
    "incar_params = run['input.doc']['input']['parameters']\n",
    "\n",
    "# Create an Incar object from the dictionary\n",
    "incar = Incar.from_dict(incar_params)\n",
    "\n",
    "# Write the INCAR file to disk\n",
    "# incar.write_file('INCAR')\n",
    "print(incar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056cf82d",
   "metadata": {},
   "source": [
    "### KPOINTS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc2219f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T14:59:49.276799Z",
     "start_time": "2023-10-31T14:59:49.271753Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get Kpoints data\n",
    "kpoints = run['output.KPOINTS']\n",
    "\n",
    "# Create a Kpoints object\n",
    "kpoints = Kpoints.gamma_automatic(kpts=kpoints, shift=(0, 0, 0))\n",
    "\n",
    "# Write the KPOINTS file to disk\n",
    "# kpoints.write_file('KPOINTS')\n",
    "print(kpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28200d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T19:54:33.763116Z",
     "start_time": "2023-10-09T19:54:33.760921Z"
    }
   },
   "source": [
    "### POTCAR files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7030c130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T15:00:08.457942Z",
     "start_time": "2023-10-31T15:00:08.451992Z"
    }
   },
   "outputs": [],
   "source": [
    "# List the POTCAR specs used\n",
    "run['input.doc']['input']['potcar_spec']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbf0909",
   "metadata": {},
   "source": [
    "## Convex Hull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92b11ed",
   "metadata": {},
   "source": [
    "The code below demonstrates how to plot the ternary/quaternary convex hull for a given compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f15e7c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T15:00:27.940529Z",
     "start_time": "2023-10-31T15:00:27.928633Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get API key\n",
    "def read_key():\n",
    "    \"\"\"\n",
    "    Read in new Materials Project API key\n",
    "    \"\"\"\n",
    "    import os, stat\n",
    "    from IPython.display import clear_output\n",
    "\n",
    "    # Read in new Materials Project API key, if one exists\n",
    "    try:\n",
    "        with open(os.path.expanduser('~/.mpkey.txt'), 'r') as f:\n",
    "            key = f.readlines()[0]\n",
    "            return key\n",
    "    except:\n",
    "        key = \"\"\n",
    "\n",
    "    # Check if API key already exists, skip try-except\n",
    "    if not key:\n",
    "        # Prompt user for API key\n",
    "        try:\n",
    "            user = str(input())\n",
    "            clear_output()\n",
    "            if not user.isalnum():\n",
    "                raise TypeError('Wrong Key')\n",
    "            if user == None:\n",
    "                raise TypeError('Empty')\n",
    "            with open(os.path.expanduser('~/.mpkey.txt'), 'w') as keyfile:\n",
    "                keyfile.write(user)\n",
    "            os.chmod(os.path.expanduser('~/.mpkey.txt'), stat.S_IREAD | stat.S_IWRITE)\n",
    "            del user\n",
    "\n",
    "            with open(os.path.expanduser('~/.mpkey.txt'),'r') as f:\n",
    "                key = f.readlines()[0]\n",
    "                return key\n",
    "            print(\"Success\")\n",
    "        except:\n",
    "            print(\"Something seems wrong with your key\")\n",
    "            \n",
    "api_key = read_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b749f1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T15:01:02.246833Z",
     "start_time": "2023-10-31T15:00:47.618735Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pymatgen.analysis.phase_diagram import PhaseDiagram, PDPlotter\n",
    "from pymatgen.entries.computed_entries import ComputedEntry\n",
    "from mp_api.client import MPRester\n",
    "\n",
    "# Instantiate the client with your API key\n",
    "mpr = MPRester(api_key)\n",
    "\n",
    "# Pick a run from the dataframe. Here, we pick one with a relatively low E_form which lies above the convex hull\n",
    "convex_hull_run = DTM_df.iloc[4]\n",
    "\n",
    "# Get run details\n",
    "structure = Structure.from_dict(convex_hull_run['structure'])\n",
    "E_form = convex_hull_run['formation_energy_per_atom']*structure.num_sites\n",
    "\n",
    "# Create a ComputedEntry object for the structure\n",
    "entry = ComputedEntry(structure.composition, E_form)\n",
    "\n",
    "chemsys = [str(e) for e in structure.composition.elements]\n",
    "\n",
    "# Get the stable phases and their energies\n",
    "entries = mpr.get_entries_in_chemsys(chemsys)\n",
    "\n",
    "print(entry)\n",
    "\n",
    "# Create a phase diagram object and add the entries\n",
    "pdi = PhaseDiagram([entry] + entries)\n",
    "\n",
    "# Plot phase diagram\n",
    "plotter = PDPlotter(pdi)\n",
    "plotter.show()\n",
    "\n",
    "print(pdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe57e826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (MatProject)",
   "language": "python",
   "name": "matproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
